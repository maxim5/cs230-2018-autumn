{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras import optimizers\n",
    "from keras.utils import np_utils\n",
    "from keras.layers import Dense, Conv2D, Embedding, Activation, MaxPooling2D, Dropout\n",
    "from keras.layers import Flatten, LSTM, ZeroPadding2D, BatchNormalization, MaxPooling2D\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part I: Image data preprocessing.\n",
    "\n",
    "In this part, you will use the popular package “skimage” to preprocess and augment an image before sending it to a neural network coded in Keras.\n",
    "\n",
    "**Question 1**:  Use skimage to load your “iguana.jpg” and display it in your notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from skimage import io\n",
    "\n",
    "# Loading the image\n",
    "### START CODE HERE ###\n",
    "image = io.imread(\"iguana.jpg\")\n",
    "plt.imshow(image)\n",
    "### END CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2**:  Use skimage to zoom on the face of the iguana. Display the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zoom image\n",
    "### START CODE HERE ###\n",
    "image_zoom = image[10:300, 300:700]\n",
    "plt.imshow(image_zoom)\n",
    "### END CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3**:  Use skimage to rescale the image to 20% of the initial size of the image. Display the image. Rescaling means lowering the resolution of the image. Remember that in class we talked about finding the computation/accuracy trade-off by showing different resolutions of the same image to humans and figuring out what is the minimum resolution leading to the maximum human accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rescale image to 25% of the initial size\n",
    "### START CODE HERE ###\n",
    "from skimage.transform import rescale\n",
    "image_rescaled = rescale(image, 1.0 / 5.0)\n",
    "plt.imshow(image_rescaled)\n",
    "### END CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4**:  Use skimage to add random noise to the image. Display the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add random noise\n",
    "### START CODE HERE ###\n",
    "from skimage.util import random_noise\n",
    "image_random_noise = random_noise(image)\n",
    "plt.imshow(image_random_noise)\n",
    "### END CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 5**:  Use skimage to rotate the image by 45 degrees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rotate\n",
    "### START CODE HERE ###\n",
    "from skimage.transform import rotate\n",
    "image_rotated = rotate(image, 45)\n",
    "plt.imshow(image_rotated)\n",
    "### END CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 6**:  Use skimage to flip the image horizontaly and verticaly. Display the image.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Horizontal flip\n",
    "### START CODE HERE ###\n",
    "image_hflip = image[:, ::-1]\n",
    "plt.imshow(image_hflip)\n",
    "### END CODE HERE ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vertical flip\n",
    "### START CODE HERE ###\n",
    "image_vflip = image[::-1, :]\n",
    "plt.imshow(image_vflip)\n",
    "### END CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 7**: (Optional) Use skimage to (i) blur the image, (ii) enhance its contrast, (iii) convert to grayscale, (iv) invert colors…"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Blur image\n",
    "### START CODE HERE ###\n",
    "from scipy import ndimage\n",
    "image_blured = ndimage.uniform_filter(image, size=(15, 15, 1))\n",
    "plt.imshow(image_blured)\n",
    "### END CODE HERE ###\n",
    "\n",
    "# Convert to grayscale\n",
    "### START CODE HERE ###\n",
    "from skimage.color import rgb2gray\n",
    "image_grayscale = rgb2gray(image)\n",
    "plt.imshow(image_grayscale)\n",
    "### END CODE HERE ###\n",
    "\n",
    "# Enhance contrast\n",
    "### START CODE HERE ###\n",
    "from skimage import exposure\n",
    "image_equalized = exposure.equalize_hist(image)\n",
    "plt.imshow(image_equalized)\n",
    "### END CODE HERE ###\n",
    "\n",
    "# Color inversion\n",
    "### START CODE HERE ###\n",
    "from skimage import util\n",
    "import numpy as np\n",
    "image_color_inv = util.invert(image)\n",
    "plt.imshow(image_color_inv)\n",
    "### END CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Skimage is a popular package for customized data preprocessing and augmentation. However, deep learning frameworks such as Keras often incorporate functions to help you preprocess data in a few lines of code. \n",
    "\n",
    "**Question 8**: Read and run the Keras code for image preprocessing. It will save augmented images in a folder called “preview” on the notebook’s directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Image preprocessing in Keras\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "        rotation_range=45,\n",
    "        width_shift_range=0.3,\n",
    "        height_shift_range=0.3,\n",
    "        shear_range=0.3,\n",
    "        zoom_range=0.3,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest')\n",
    "\n",
    "img = load_img('iguana.jpg')  # this is a PIL image\n",
    "x = img_to_array(img)  # convert image to numpy array \n",
    "x = x.reshape((1,) + x.shape)  # reshape image to (1, ..,..,..) to fit keras' standard shape\n",
    "\n",
    "# Use flow() to apply data augmentation randomly according to the datagenerator\n",
    "# and saves the results to the `preview/` directory\n",
    "num_image_generated = 0\n",
    "for batch in datagen.flow(x, batch_size=1, save_to_dir='preview', save_prefix='cat', save_format='jpeg'):\n",
    "    num_image_generated += 1\n",
    "    if num_image_generated > 20:\n",
    "        break # stop the loop after num_image_generated iterations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 9** : Observe images generated in the preview folder. Similarly to \"iguana.jpeg\", augment the image \"lion.jpeg\". Save the images in a \"preview_lion\" folder.\n",
    "\n",
    "**Question 10** : We will know show you a trick to create a numpy array of images and labels (0 for non-iguana, 1 for iguana). We will then pass the numpy arrays to the CNN to train in mini-batches of size 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code that generates the labels.\n",
    "import os\n",
    "from scipy import ndimage, misc\n",
    "\n",
    "images = []\n",
    "labels = []\n",
    "for root, dirnames, filenames in os.walk(\"preview/\"):\n",
    "    for filename in filenames:\n",
    "        if re.search(\"\\.(jpg|jpeg|png|bmp|tiff)$\", filename):\n",
    "            filepath = os.path.join(root, filename)\n",
    "            image = ndimage.imread(filepath, mode=\"RGB\")\n",
    "            image_resized = misc.imresize(image, (100, 100))\n",
    "            images.append(image_resized)\n",
    "            labels.append(float(filename[0]))\n",
    "            \n",
    "images = np.array(images)\n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(images.shape)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 11**: (Optional) Evaluate the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part II: Text data preprocessing.\n",
    "**Question 1**: Go on any static website online. Click right and select “View Page Source”. Copy a complicated part of the html code. Paste it in the notebook in the variable “html_page”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### START CODE HERE ###\n",
    "html_txt = \"\"\"<div class=\"jumbotron jumbotron-fluid\">\n",
    "      <div class=\"container\">\n",
    "      <h1 class=\"display-5\">CS230: Deep Learning</h1>\n",
    "      <h2 class=\"display-7\">Spring 2018</h2><h3>Instructors</h3>\n",
    "      <div class=\"row\">\n",
    "        <div class=\"instructor\">\n",
    "          <a href=\"#\">\n",
    "            <img class=\"headshot\" src=\"static/andrew.jpg\" style=\"text-align:center;\">\n",
    "            <div style=\"text-align:center;\"><a href=\"http://www.andrewng.org/\">Andrew Ng</a></div>\n",
    "          </a>\n",
    "        </div>\n",
    "        <div class=\"instructor\">\n",
    "          <a href=\"#\">\n",
    "            <img class=\"headshot\" src=\"static/kian.jpg\" style=\"text-align:center;\">\n",
    "            <div style=\"text-align:center;\"><a href=\"https://www.linkedin.com/in/kiankatan/\">Kian Katanforoosh</a></div>\n",
    "          </a>\n",
    "        </div>\n",
    "      </div>\n",
    "      <br />\n",
    "      <p><strong>Course Description</strong>&nbsp;&nbsp; Deep Learning is one of the most highly sought after skills in AI. We will help you become good at Deep Learning. In this course, you will learn the foundations of Deep Learning, understand how to build neural networks, and learn how to lead successful machine learning projects. You will learn about Convolutional networks, RNNs, LSTM, Adam, Dropout, BatchNorm, Xavier/He initialization, and more. You will work on case studies from healthcare, autonomous driving, sign language reading, music generation, and natural language processing. You will master not only the theory, but also see how it is applied in industry. You will practice all these ideas in Python and in TensorFlow, which we will teach. \n",
    "      After this course, you will likely find creative ways to apply it to your work. This class is taught in the flipped-classroom format. You will watch videos and complete in-depth programming assignments and online quizzes at home, then come to class for advanced discussions and work on projects.\n",
    "      This class will culminate in an open-ended final project, which the teaching team will help you on. </p>\n",
    "    </div>\n",
    "\n",
    "  <div style=\"text-align:center; padding:40px 0px 0px 0px;\">\n",
    "      <a href=\"./syllabus.html\">\n",
    "      <button type=\"button\" class=\"btn btn-success btn-lg\">Schedule</button>\n",
    "      </a>\n",
    "      <a href=\"http://piazza.com/stanford/spring/cs230\">\n",
    "      <button type=\"button\" class=\"btn btn-danger btn-lg\">Piazza Forum</button>\n",
    "      </a>\n",
    "      <a href=\"./calendar.html\">\n",
    "      <button type=\"button\" class=\"btn btn-info btn-lg\">OH Calendar</button>\n",
    "      </a>\n",
    "      <!-- <a href=\"#\">\n",
    "      <button type=\"button\" class=\"btn btn-info btn-lg\">Calendar</button>\n",
    "      </a> -->\n",
    "  </div>\n",
    "  </div>\"\"\"\n",
    "### END CODE HERE ###\n",
    "\n",
    "print(html_txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2**: Use *BeautifulSoup* to parse the html_txt. Print the html_txt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Parse the html input\n",
    "### START CODE HERE ###\n",
    "def parse_html(html_page):\n",
    "    soup = BeautifulSoup(html_page, \"html.parser\")\n",
    "    return soup.get_text()\n",
    "html_txt = parse_html(html_txt)\n",
    "### END CODE HERE ###\n",
    "\n",
    "print(html_txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3**: Use *re* to remove meta-characters such as squared brackets and anything between them. Print the html_txt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, string, unicodedata\n",
    "# Remove meta characters and things between them.\n",
    "### START CODE HERE ###\n",
    "def remove_between_square_brackets(html_page):\n",
    "    return re.sub('\\[[^]]*\\]', '', html_page)\n",
    "\n",
    "html_txt = remove_between_square_brackets(html_txt)\n",
    "### END CODE HERE ###\n",
    "\n",
    "print(html_txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4**: Using the Natural Language ToolKit (nltk), separate the text into a list of words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk import word_tokenize, sent_tokenize\n",
    "\n",
    "# Separate text into words\n",
    "### START CODE HERE ###\n",
    "words = nltk.word_tokenize(html_txt)\n",
    "print(words)\n",
    "### END CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 5**: (Optional) Remove non ASCII characters. Convert to Lower case. Remove punctuation, stopwords, …"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### START CODE HERE ###\n",
    "\n",
    "### END CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A machine will not be able to read this list strings, you need to build a vocabulary and tokenize your words.\n",
    "\n",
    "**Question 6**: Build the vocabulary from the list of words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build Vocabulary\n",
    "### START CODE HERE ###\n",
    "vocabulary = sorted(set(words))\n",
    "print(vocabulary)\n",
    "print(len(vocabulary))\n",
    "### END CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 7**: Build word to integer mapping in Python. It should be sorted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Build word to integer mapping in Python. It should be sorted.\n",
    "### START CODE HERE ###\n",
    "word_to_int = dict((c, i) for i, c in enumerate(sorted(words)))\n",
    "print(word_to_int)\n",
    "### END CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 8**: Tokenize your text. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert list of words into list of tokens using this mapping\n",
    "### START CODE HERE ###\n",
    "tokens = [ word_to_int[x] for x in words]\n",
    "print(tokens)\n",
    "### END CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 9**: Read and run the Keras code for text preprocessing. It uses the Tokenizer Function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess text with Keras for Sentiment classification\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "examples = ['You are amazing!','It is so bad','Congratulations','You suck bro','Awesome dude!']\n",
    "Y = [1, 0, 1, 0, 1]\n",
    "\n",
    "# Define Tokenizer\n",
    "t = Tokenizer()\n",
    "# Fit Tokenizer on text (Build vocab etc..)\n",
    "t.fit_on_texts(examples)\n",
    "# Convert texts to sequences of integers\n",
    "X = t.texts_to_sequences(examples)\n",
    "# Pad sequences of integers\n",
    "X = pad_sequences(X, padding = 'post')\n",
    "\n",
    "# Get the vocabulary size, useful for the embedding layer.\n",
    "vocab_size = len(t.word_index) + 1\n",
    "print(vocab_size)\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 10**: (Optional) Train the RNN coded for you in the notebook on the sentiment classification class (with 5 examples). Evaluate the mode."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix: Models and training codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# CNN\n",
    "model_CNN = Sequential()\n",
    "model_CNN.add(Conv2D(32, (7, 7), strides = (3, 3), name = 'conv0', input_shape = images[0].shape))\n",
    "model_CNN.add(BatchNormalization(axis = 3, name = 'bn0'))\n",
    "model_CNN.add(Activation('relu'))\n",
    "model_CNN.add(Conv2D(32, (5, 5), strides = (3, 3), name = 'conv1', input_shape = images[0].shape))\n",
    "model_CNN.add(BatchNormalization(axis = 3, name = 'bn1'))\n",
    "model_CNN.add(Activation('relu'))\n",
    "model_CNN.add(Conv2D(32, (3, 3), strides = (2, 2), name = 'conv2', input_shape = images[0].shape))\n",
    "model_CNN.add(BatchNormalization(axis = 3, name = 'bn2'))\n",
    "model_CNN.add(Activation('relu'))\n",
    "model_CNN.add(MaxPooling2D((2, 2), name='max_pool'))\n",
    "model_CNN.add(Flatten())\n",
    "model_CNN.add(Dense(1, activation='sigmoid', name='fc'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# RNN\n",
    "model_RNN = Sequential()\n",
    "model_RNN.add(Embedding(vocab_size, 128))\n",
    "model_RNN.add(LSTM(128))\n",
    "model_RNN.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# training code for CNN\n",
    "sgd = optimizers.SGD(lr=0.001, decay=1e-6, momentum=0.9)\n",
    "model_CNN.compile(loss='binary_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "model_CNN.fit(images, labels, epochs = 10, batch_size = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training code for RNN\n",
    "sgd = optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9)\n",
    "model_RNN.compile(loss='binary_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "model_RNN.fit(np.array(X), np.array(Y), epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing code for CNN\n",
    "print(model_CNN.predict(images))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix 2: Example of use of a data generator in Keras\n",
    "\n",
    "Code from the official Keras documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.datasets import cifar10\n",
    "from keras.utils import np_utils\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN for datagen\n",
    "model_CNN = Sequential()\n",
    "model_CNN.add(Conv2D(32, (7, 7), strides = (3, 3), name = 'conv0', input_shape = (100,100,3)))\n",
    "model_CNN.add(BatchNormalization(axis = 3, name = 'bn0'))\n",
    "model_CNN.add(Activation('relu'))\n",
    "model_CNN.add(Conv2D(32, (5, 5), strides = (3, 3), name = 'conv1'))\n",
    "model_CNN.add(BatchNormalization(axis = 3, name = 'bn1'))\n",
    "model_CNN.add(Activation('relu'))\n",
    "model_CNN.add(Conv2D(32, (3, 3), strides = (2, 2), name = 'conv2'))\n",
    "model_CNN.add(BatchNormalization(axis = 3, name = 'bn2'))\n",
    "model_CNN.add(Activation('relu'))\n",
    "model_CNN.add(MaxPooling2D((2, 2), name='max_pool'))\n",
    "model_CNN.add(Flatten())\n",
    "model_CNN.add(Dense(1, activation='sigmoid', name='fc'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 10\n",
    "y_train = np_utils.to_categorical(y_train, num_classes)\n",
    "y_test = np_utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    featurewise_center=True,\n",
    "    featurewise_std_normalization=True,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "# compute quantities required for featurewise normalization\n",
    "# (std, mean, and principal components if ZCA whitening is applied)\n",
    "datagen.fit(x_train)\n",
    "\n",
    "# fits the model on batches with real-time data augmentation:\n",
    "epochs = 10\n",
    "model_CNN.fit_generator(datagen.flow(x_train, y_train, batch_size=32),\n",
    "                    steps_per_epoch=len(x_train) / 32, epochs=epochs)\n",
    "\n",
    "# here's a more \"manual\" example\n",
    "for e in range(epochs):\n",
    "    print('Epoch', e)\n",
    "    batches = 0\n",
    "    for x_batch, y_batch in datagen.flow(x_train, y_train, batch_size=32):\n",
    "        model_CNN.fit(x_batch, y_batch)\n",
    "        batches += 1\n",
    "        if batches >= len(x_train) / 32:\n",
    "            # we need to break the loop by hand because\n",
    "            # the generator loops indefinitely\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
