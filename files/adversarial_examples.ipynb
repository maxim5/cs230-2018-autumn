{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adversarial Examples\n",
    "\n",
    "In this example, we will do the following steps:\n",
    "- Generate a 1D dataset with 2 classes sampled from Gaussian Distribution with different means\n",
    "- Train a Logistic Regression Classifier on this dataset\n",
    "- Generate a naive Adversarial Example (i.e. Classifier thinks it's new class but example no longer looks anything remotely like the original class)\n",
    "- Generate a better Adversarial Example (i.e. Classifier thinks it's new class but example still looks like original class!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Generate Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dataset(mu, sigma, examples):\n",
    "    return np.random.normal(mu, sigma, examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu1 = -1\n",
    "mu2 = 2\n",
    "sigma = 1\n",
    "m = 100\n",
    "\n",
    "def generate_full_dataset():\n",
    "    x1 = generate_dataset(mu1, sigma, m)\n",
    "    x2 = generate_dataset(mu2, sigma, m)\n",
    "    _x = np.expand_dims(np.hstack((x1,x2)), axis=1)\n",
    "    x = np.hstack((np.ones((2*m,1)), _x))\n",
    "    y = np.vstack((np.zeros((m,1)), np.ones((m,1))))\n",
    "    return x1, x2, x, y\n",
    "\n",
    "x1, x2, x, y = generate_full_dataset()\n",
    "_, _, test_x, test_y = generate_full_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_distribution(mu, sigma, s, color):\n",
    "    count, bins, ignored = plt.hist(s, 20, normed=True, color=color)\n",
    "    plt.plot(bins, 1/(sigma * np.sqrt(2 * np.pi)) *\n",
    "        np.exp( - (bins - mu)**2 / (2 * sigma**2) ),\n",
    "        linewidth=2, color=color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11450b5f8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_distribution(mu1, sigma, x1, 'r')\n",
    "plot_distribution(mu2, sigma, x2, 'g')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Train Classifier using Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_variables():\n",
    "    w = np.random.randn(2,1)\n",
    "    return w\n",
    "\n",
    "def forward_prop(w, x):\n",
    "    def sigmoid(z):\n",
    "        return 1.0/(1 + np.exp(-z))\n",
    "    return sigmoid(np.matmul(x,w))\n",
    "    \n",
    "def backward_prop(w, x, y, y_hat, learning_rate=0.01):\n",
    "    dw = np.matmul(x.T, y_hat - y)\n",
    "    w_new = w - learning_rate * dw\n",
    "    return w_new\n",
    "\n",
    "def get_class(y_hat):\n",
    "    return y_hat >= 0.5\n",
    "\n",
    "def calc_binary_cross_entropy_loss(y_hat, y):\n",
    "    return -np.sum(y * np.log(y_hat) + (1-y) * np.log(1-y_hat))\n",
    "\n",
    "def calc_accuracy(y_hat, y):\n",
    "    return np.sum(y*(y_hat>=0.5) + (1-y)*(y_hat<0.5))/y.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_performance(itr, y_hat, y, dataset_type='Train'):\n",
    "    loss = calc_binary_cross_entropy_loss(y_hat, y)\n",
    "    accuracy = calc_accuracy(y_hat, y)\n",
    "    print('Iteration {} | {} Loss: {} | {} Accuracy: {}'.format(\n",
    "        itr, dataset_type, loss, dataset_type, accuracy))\n",
    "    \n",
    "def training_loop(num_iters, x, y, print_every=1):\n",
    "    w = initialize_variables()\n",
    "    for itr in range(num_iters):\n",
    "        y_hat = forward_prop(w, x)\n",
    "        if itr%print_every == 0:\n",
    "            print_performance(itr, y_hat, y)\n",
    "        w = backward_prop(w, x, y, y_hat)\n",
    "    test_y_hat = forward_prop(w, test_x)\n",
    "#     print_performance('End', test_y_hat, test_y, 'Test')\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0 | Train Loss: 164.46693309520944 | Train Accuracy: 0.5\n",
      "Iteration 1 | Train Loss: 32.2025858558397 | Train Accuracy: 0.935\n",
      "Iteration 2 | Train Loss: 31.231327311117777 | Train Accuracy: 0.935\n",
      "Iteration 3 | Train Loss: 30.46874124981169 | Train Accuracy: 0.935\n",
      "Iteration 4 | Train Loss: 29.85248822421606 | Train Accuracy: 0.935\n",
      "Iteration 5 | Train Loss: 29.343740443231393 | Train Accuracy: 0.935\n",
      "Iteration 6 | Train Loss: 28.916736879761398 | Train Accuracy: 0.935\n",
      "Iteration 7 | Train Loss: 28.553557771493992 | Train Accuracy: 0.935\n",
      "Iteration 8 | Train Loss: 28.24127204034748 | Train Accuracy: 0.935\n",
      "Iteration 9 | Train Loss: 27.970271568113578 | Train Accuracy: 0.94\n"
     ]
    }
   ],
   "source": [
    "w = training_loop(10, x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEZEYUrmLiMTQ/wNPD+E0QD1fKAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x117b477f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def find_boundary(w):\n",
    "    return -w[0]/w[1]\n",
    "\n",
    "plot_distribution(mu1, sigma, x1, 'r')\n",
    "plot_distribution(mu2, sigma, x2, 'g')\n",
    "plt.axvline(x=find_boundary(w))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Naive Adversarial Example\n",
    "\n",
    "To generate an adversarial example w.r.t. class 0, we need to take derivatives of the loss w.r.t. an example of class 1. If we simply change the label to 0 and change the input, the classifier will classify it as class 0 eventually. However, the example no longer \"looks like\" it's from class 0.\n",
    "\n",
    "In this example, we assume that to humans, any input that is negative looks like it's from class 0, while any input that is positive looks like it's from class 1.\n",
    "\n",
    "The loss below is taken from the lecture slides. In our case, we are doing classification so we use BCE loss instead of L2 loss."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](img/naive_adversarial.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example: [[1 2]] | Class: [ True] | Loss: 0.025447496903977174\n"
     ]
    }
   ],
   "source": [
    "start_example = np.array([[1,mu2]])\n",
    "y_hat = forward_prop(w, start_example)\n",
    "y = np.array([[1]])\n",
    "correct_loss = calc_binary_cross_entropy_loss(y_hat, y)\n",
    "print(\"Example: {} | Class: {} | Loss: {}\".format(start_example, get_class(y_hat)[0], correct_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example: [[1 2]] | Adversarial Loss: 3.6838346606027472\n"
     ]
    }
   ],
   "source": [
    "y = np.array([[0]])\n",
    "adversarial_loss = calc_binary_cross_entropy_loss(y_hat, y)\n",
    "print(\"Example: {} | Adversarial Loss: {}\".format(start_example, adversarial_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def looks_like_original(x_new, x_orig):\n",
    "    # Returns true if x_new and x_orig have same sign\n",
    "    return (x_new > 0) * (x_orig > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward_prop_to_input(w, x, y, y_hat, learning_rate=0.1):\n",
    "    # Only works for single input x for now\n",
    "    dx = np.matmul(y_hat - y, w.T)\n",
    "    x_new = x - learning_rate * dx\n",
    "    x_new[0][0] = 1 # zeroth feature should not get updated!\n",
    "    return x_new\n",
    "\n",
    "def print_adversarial_performance(itr, y_hat, y, x_new, x_orig, dataset_type='Train'):\n",
    "    loss = calc_binary_cross_entropy_loss(y_hat, y)\n",
    "    accuracy = calc_accuracy(y_hat, y)\n",
    "    print('Iteration {} | {} Loss: {} | {} Accuracy: {} | New Image Looks Like Original: {}'.format(\n",
    "        itr, dataset_type, loss, dataset_type, accuracy, looks_like_original(x_new, x_orig)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_adversarial_training_loop(x, w, num_iters, print_every=1):\n",
    "    print(\"Starting Example: {}\".format(x))\n",
    "    for itr in range(num_iters):\n",
    "        y_hat = forward_prop(w, x)\n",
    "        if itr%print_every == 0:\n",
    "            print_adversarial_performance(itr, y_hat, y, x[0][1], start_example[0][1])\n",
    "        x = backward_prop_to_input(w, x, y, y_hat)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Example: [[1 2]]\n",
      "Iteration 0 | Train Loss: 3.6838346606027472 | Train Accuracy: 0.0 | New Image Looks Like Original: True\n",
      "Iteration 5 | Train Loss: 1.3534110651616833 | Train Accuracy: 0.0 | New Image Looks Like Original: True\n",
      "Iteration 10 | Train Loss: 0.44586928330933895 | Train Accuracy: 1.0 | New Image Looks Like Original: True\n",
      "Iteration 15 | Train Loss: 0.22333954914043774 | Train Accuracy: 1.0 | New Image Looks Like Original: False\n",
      "Iteration 20 | Train Loss: 0.143456511087206 | Train Accuracy: 1.0 | New Image Looks Like Original: False\n",
      "Iteration 25 | Train Loss: 0.10443136635318857 | Train Accuracy: 1.0 | New Image Looks Like Original: False\n",
      "Iteration 30 | Train Loss: 0.08169477341203468 | Train Accuracy: 1.0 | New Image Looks Like Original: False\n",
      "Iteration 35 | Train Loss: 0.06692174954613377 | Train Accuracy: 1.0 | New Image Looks Like Original: False\n",
      "Iteration 40 | Train Loss: 0.05659298383937963 | Train Accuracy: 1.0 | New Image Looks Like Original: False\n",
      "Iteration 45 | Train Loss: 0.048982969375009996 | Train Accuracy: 1.0 | New Image Looks Like Original: False\n"
     ]
    }
   ],
   "source": [
    "new_example = naive_adversarial_training_loop(start_example, w, 50, print_every=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Example\n",
      "Example: 2\n",
      "Looks like Original: True\n",
      "Black Box Class: 1\n",
      "\n",
      "Adversarial Example\n",
      "Example: -0.8385584344513204\n",
      "Looks like Original: False\n",
      "Black Box Class: 0\n"
     ]
    }
   ],
   "source": [
    "# Adversarial Example using Sign Gradient Method works!\n",
    "print (\"Start Example\")\n",
    "print(\"Example: {}\".format(start_example[0][1]))\n",
    "print(\"Looks like Original: {}\".format(looks_like_original(start_example[0][1], start_example[0][1])))\n",
    "print(\"Black Box Class: {}\".format(1 if get_class(forward_prop(w, start_example))[0][0] else 0))\n",
    "print()\n",
    "print(\"Adversarial Example\")\n",
    "print(\"Example: {}\".format(new_example[0][1]))\n",
    "print(\"Looks like Original: {}\".format(looks_like_original(new_example[0][1], start_example[0][1])))\n",
    "print(\"Black Box Class: {}\".format(1 if get_class(forward_prop(w, new_example))[0][0] else 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Better Adversarial Example\n",
    "\n",
    "As seen in the above example, while the classifier classifies the new example as class 0, the new example no longer \"looks like\" the original example.\n",
    "\n",
    "We change our loss to include the squared difference between the new example and the original example. We show that in this way, we are able to generate an adversarial example which the classifier classifies as class 0 even though the new example still \"looks like\" the original example.\n",
    "\n",
    "Like before, we change the first term to BCE loss. We keep the second term the same (L2 loss over features)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](img/better_adversarial.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def better_backward_prop_to_input(w, x, x_orig, y, y_hat, learning_rate=0.1, lambd=1.0):\n",
    "    # Only works for single input x for now\n",
    "    dx = np.matmul(y_hat - y, w.T) + 2 * lambd * (x[0] - x_orig[0])\n",
    "    x_new = x - learning_rate * dx\n",
    "    x_new[0][0] = 1 # zeroth feature should not get updated!\n",
    "    return x_new\n",
    "\n",
    "# def calc_better_adversarial_loss(y_hat, y, x_new, x_orig, lambd=1.0):\n",
    "#     return calc_binary_cross_entropy_loss(y_hat, y) + \\\n",
    "#             lambd * (np.square(x_new - x_orig))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def better_adversarial_training_loop(x, w, num_iters, print_every=1, lambd=1.0):\n",
    "    print(\"Starting Example: {}\".format(x))\n",
    "    for itr in range(num_iters):\n",
    "        y_hat = forward_prop(w, x)\n",
    "        if itr%print_every == 0:\n",
    "            print_adversarial_performance(itr, y_hat, y, x[0][1], start_example[0][1])\n",
    "        x = better_backward_prop_to_input(w, x, start_example, y, y_hat, lambd=lambd)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Example: [[1 2]]\n",
      "Iteration 0 | Train Loss: 3.6838346606027472 | Train Accuracy: 0.0 | New Image Looks Like Original: True\n",
      "Iteration 5 | Train Loss: 1.5369495377266704 | Train Accuracy: 0.0 | New Image Looks Like Original: True\n",
      "Iteration 10 | Train Loss: 0.7514180035844698 | Train Accuracy: 0.0 | New Image Looks Like Original: True\n",
      "Iteration 15 | Train Loss: 0.5499689289278108 | Train Accuracy: 1.0 | New Image Looks Like Original: True\n",
      "Iteration 20 | Train Loss: 0.49015912846255727 | Train Accuracy: 1.0 | New Image Looks Like Original: True\n",
      "Iteration 25 | Train Loss: 0.4700593376221668 | Train Accuracy: 1.0 | New Image Looks Like Original: True\n",
      "Iteration 30 | Train Loss: 0.4629486863450584 | Train Accuracy: 1.0 | New Image Looks Like Original: True\n",
      "Iteration 35 | Train Loss: 0.46038417787249586 | Train Accuracy: 1.0 | New Image Looks Like Original: True\n",
      "Iteration 40 | Train Loss: 0.45945268127415007 | Train Accuracy: 1.0 | New Image Looks Like Original: True\n",
      "Iteration 45 | Train Loss: 0.4591134577489157 | Train Accuracy: 1.0 | New Image Looks Like Original: True\n"
     ]
    }
   ],
   "source": [
    "new_example = better_adversarial_training_loop(start_example, w, 50, print_every=5, lambd=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Example\n",
      "Example: 2\n",
      "Looks like Original: True\n",
      "Black Box Class: 1\n",
      "\n",
      "Adversarial Example\n",
      "Example: 0.24201883671021976\n",
      "Looks like Original: True\n",
      "Black Box Class: 0\n"
     ]
    }
   ],
   "source": [
    "# Adversarial Example using Sign Gradient Method works!\n",
    "print (\"Start Example\")\n",
    "print(\"Example: {}\".format(start_example[0][1]))\n",
    "print(\"Looks like Original: {}\".format(looks_like_original(start_example[0][1], start_example[0][1])))\n",
    "print(\"Black Box Class: {}\".format(1 if get_class(forward_prop(w, start_example))[0][0] else 0))\n",
    "print()\n",
    "print(\"Adversarial Example\")\n",
    "print(\"Example: {}\".format(new_example[0][1]))\n",
    "print(\"Looks like Original: {}\".format(looks_like_original(new_example[0][1], start_example[0][1])))\n",
    "print(\"Black Box Class: {}\".format(1 if get_class(forward_prop(w, new_example))[0][0] else 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](img/space_of_adversarial_examples.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Black Box vs White Box Attacks\n",
    "\n",
    "We have seen an example of a \"White Box Attack\" since we have access to the original classifier's architecture and weights. Now, let's see how one may perform a \"Black Box Attack\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0 | Train Loss: 252.920981783054 | Train Accuracy: 0.6159149131954049\n",
      "Iteration 1 | Train Loss: 141.51855865832619 | Train Accuracy: 0.8534250366651536\n",
      "Iteration 2 | Train Loss: 136.28026988788724 | Train Accuracy: 0.8565799925441653\n",
      "Iteration 3 | Train Loss: 133.97567139031787 | Train Accuracy: 0.8572792278743205\n",
      "Iteration 4 | Train Loss: 132.75367277756658 | Train Accuracy: 0.8575970679366708\n",
      "Iteration 5 | Train Loss: 132.04248399898873 | Train Accuracy: 0.8577113450109521\n",
      "Iteration 6 | Train Loss: 131.6047552658429 | Train Accuracy: 0.8577958139397198\n",
      "Iteration 7 | Train Loss: 131.32503217904733 | Train Accuracy: 0.8577958139397198\n",
      "Iteration 8 | Train Loss: 131.14141256561805 | Train Accuracy: 0.8578504506592182\n",
      "Iteration 9 | Train Loss: 131.01843876606216 | Train Accuracy: 0.8578504506592182\n"
     ]
    }
   ],
   "source": [
    "# Generate dataset and forward prop in black box classifier to get corresponding labels\n",
    "_gen_x = np.arange(-2,2,0.01)\n",
    "gen_x = np.vstack((np.ones(_gen_x.shape), _gen_x)).T\n",
    "gen_y = forward_prop(w, gen_x)\n",
    "\n",
    "# Train our own network on generated dataset\n",
    "gen_w = training_loop(10, gen_x, gen_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Example: [[1 2]]\n",
      "Iteration 0 | Train Loss: 3.5130019907812327 | Train Accuracy: 0.0 | New Image Looks Like Original: True\n",
      "Iteration 5 | Train Loss: 1.6014819059728957 | Train Accuracy: 0.0 | New Image Looks Like Original: True\n",
      "Iteration 10 | Train Loss: 0.8313043306093468 | Train Accuracy: 0.0 | New Image Looks Like Original: True\n",
      "Iteration 15 | Train Loss: 0.60502368539474 | Train Accuracy: 1.0 | New Image Looks Like Original: True\n",
      "Iteration 20 | Train Loss: 0.532067738614782 | Train Accuracy: 1.0 | New Image Looks Like Original: True\n",
      "Iteration 25 | Train Loss: 0.5058422876242678 | Train Accuracy: 1.0 | New Image Looks Like Original: True\n",
      "Iteration 30 | Train Loss: 0.49591677103168713 | Train Accuracy: 1.0 | New Image Looks Like Original: True\n",
      "Iteration 35 | Train Loss: 0.49207969796297546 | Train Accuracy: 1.0 | New Image Looks Like Original: True\n",
      "Iteration 40 | Train Loss: 0.49058373867242994 | Train Accuracy: 1.0 | New Image Looks Like Original: True\n",
      "Iteration 45 | Train Loss: 0.4899985608377433 | Train Accuracy: 1.0 | New Image Looks Like Original: True\n"
     ]
    }
   ],
   "source": [
    "# Create adversarial example on own network\n",
    "new_example = better_adversarial_training_loop(start_example, gen_w, 50, print_every=5, lambd=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Example\n",
      "Example: 2\n",
      "Looks like Original: True\n",
      "Black Box Class: 1\n",
      "\n",
      "Adversarial Example\n",
      "Example: 0.2530884487558152\n",
      "Looks like Original: True\n",
      "Black Box Class: 0\n"
     ]
    }
   ],
   "source": [
    "# Adversarial Example transfers to black box classifier!\n",
    "print (\"Start Example\")\n",
    "print(\"Example: {}\".format(start_example[0][1]))\n",
    "print(\"Looks like Original: {}\".format(looks_like_original(start_example[0][1], start_example[0][1])))\n",
    "print(\"Black Box Class: {}\".format(1 if get_class(forward_prop(w, start_example))[0][0] else 0))\n",
    "print()\n",
    "print(\"Adversarial Example\")\n",
    "print(\"Example: {}\".format(new_example[0][1]))\n",
    "print(\"Looks like Original: {}\".format(looks_like_original(new_example[0][1], start_example[0][1])))\n",
    "print(\"Black Box Class: {}\".format(1 if get_class(forward_prop(w, new_example))[0][0] else 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Targeted vs Non-Targeted Attacks\n",
    "\n",
    "In this example, there are only 2 classes. If there are k classes, a targeted attack is trying to fool the network into thinking an example comes from a specific class j even though it \"looks like\" it's from class i. A non-targeted attack is trying to fool the network into thinking an example comes from any class j!=i even though it \"looks like\" it's from class i."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fast Gradient Sign Method\n",
    "\n",
    "In the following example, we showcase the fast gradient sign method. This method comes from the insight that if we modify the input in the direction of the negative sign of the gradient of loss w.r.t. input, we can generate an adversarial example. This method works better when:\n",
    "- Weights are large in magnitude\n",
    "- More dimensions\n",
    "\n",
    "In this case, we have only one dimension. Hence, we need to use eps=1.8 (pretty large) to generate the adversarial example. You can try adding more dimensions and you'll realize that a smaller eps will work there!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_adversarial_example_using_gradient_sign_method(w, x, y, y_hat, eps=1.0):\n",
    "    dx = np.matmul(y_hat - y, w.T)\n",
    "    x_new = x - eps * np.sign(dx)\n",
    "    x_new[0][0] = 1\n",
    "    return x_new\n",
    "y_hat = forward_prop(w, start_example)\n",
    "new_example = generate_adversarial_example_using_gradient_sign_method(w, start_example, 0, y_hat, eps=1.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Example\n",
      "Example: 2\n",
      "Looks like Original: True\n",
      "Black Box Class: 1\n",
      "\n",
      "Adversarial Example\n",
      "Example: 0.19999999999999996\n",
      "Looks like Original: True\n",
      "Black Box Class: 0\n"
     ]
    }
   ],
   "source": [
    "# Adversarial Example using Sign Gradient Method works!\n",
    "print (\"Start Example\")\n",
    "print(\"Example: {}\".format(start_example[0][1]))\n",
    "print(\"Looks like Original: {}\".format(looks_like_original(start_example[0][1], start_example[0][1])))\n",
    "print(\"Black Box Class: {}\".format(1 if get_class(forward_prop(w, start_example))[0][0] else 0))\n",
    "print()\n",
    "print(\"Adversarial Example\")\n",
    "print(\"Example: {}\".format(new_example[0][1]))\n",
    "print(\"Looks like Original: {}\".format(looks_like_original(new_example[0][1], start_example[0][1])))\n",
    "print(\"Black Box Class: {}\".format(1 if get_class(forward_prop(w, new_example))[0][0] else 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
